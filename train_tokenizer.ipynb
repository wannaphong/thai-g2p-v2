{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1cc56d",
   "metadata": {},
   "source": [
    "   Copyright 2016-2024 Wannaphong Phatthiyaphaibun\n",
    "\n",
    "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "   you may not use this file except in compliance with the License.\n",
    "   You may obtain a copy of the License at\n",
    "\n",
    "       http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "   Unless required by applicable law or agreed to in writing, software\n",
    "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "   See the License for the specific language governing permissions and\n",
    "   limitations under the License.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73c5e53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-12 13:38:09--  https://github.com/PyThaiNLP/thai-g2p-wiktionary-corpus/raw/main/wiktionary-23-7-2022-clean.tsv\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/PyThaiNLP/thai-g2p-wiktionary-corpus/main/wiktionary-23-7-2022-clean.tsv [following]\n",
      "--2023-01-12 13:38:10--  https://raw.githubusercontent.com/PyThaiNLP/thai-g2p-wiktionary-corpus/main/wiktionary-23-7-2022-clean.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 858538 (838K) [text/plain]\n",
      "Saving to: ‘wiktionary-23-7-2022-clean.tsv’\n",
      "\n",
      "wiktionary-23-7-202 100%[===================>] 838.42K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2023-01-12 13:38:12 (15.8 MB/s) - ‘wiktionary-23-7-2022-clean.tsv’ saved [858538/858538]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/PyThaiNLP/thai-g2p-wiktionary-corpus/raw/main/wiktionary-23-7-2022-clean.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03610f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c489fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wiktionary-23-7-2022-clean.tsv\",sep=\"\\t\",names=[\"grapheme\",\"phoneme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "656f1107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grapheme</th>\n",
       "      <th>phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ก</td>\n",
       "      <td>k ɔː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ก.</td>\n",
       "      <td>k ɔː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ก.ค.</td>\n",
       "      <td>k ɔː ˧ . kʰ ɔː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ก.ท.ม.</td>\n",
       "      <td>k ɔː ˧ . tʰ ɔː ˧ . m ɔː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ก.พ.</td>\n",
       "      <td>k ɔː ˧ . pʰ ɔː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>ไฮโซ</td>\n",
       "      <td>h aj ˧ . s oː ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16024</th>\n",
       "      <td>ไฮโดรคาร์บอน</td>\n",
       "      <td>h aj ˧ . d r oː ˧ . kʰ aː ˧ . b ɔ n ˥˩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16025</th>\n",
       "      <td>ไฮโดรเจน</td>\n",
       "      <td>h aj ˧ . d r oː ˧ . t͡ɕ eː n ˧</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16026</th>\n",
       "      <td>ไฮโดรเจน</td>\n",
       "      <td>h aj ˧ . d r oː ˧ . t͡ɕ e n ˥˩</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>ไฮ้</td>\n",
       "      <td>h aj ˦˥</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           grapheme                                 phoneme\n",
       "0                 ก                                  k ɔː ˧\n",
       "1                ก.                                  k ɔː ˧\n",
       "2              ก.ค.                        k ɔː ˧ . kʰ ɔː ˧\n",
       "3            ก.ท.ม.               k ɔː ˧ . tʰ ɔː ˧ . m ɔː ˧\n",
       "4              ก.พ.                        k ɔː ˧ . pʰ ɔː ˧\n",
       "...             ...                                     ...\n",
       "16023          ไฮโซ                         h aj ˧ . s oː ˧\n",
       "16024  ไฮโดรคาร์บอน  h aj ˧ . d r oː ˧ . kʰ aː ˧ . b ɔ n ˥˩\n",
       "16025      ไฮโดรเจน          h aj ˧ . d r oː ˧ . t͡ɕ eː n ˧\n",
       "16026      ไฮโดรเจน          h aj ˧ . d r oː ˧ . t͡ɕ e n ˥˩\n",
       "16027           ไฮ้                                 h aj ˦˥\n",
       "\n",
       "[16028 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab8c45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16028, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "013396d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15956, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9616564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14839, 15250)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grapheme.nunique(),df.phoneme.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e28dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wiktionary_dedup.csv',header=None, index=None, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c3aad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e314308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank https://github.com/LalitaDeelert/lalita-mt-zhth/blob/main/notebooks/huggingface_tutorial.ipynb\n",
    "train,test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train,val= train_test_split(train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ceab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.tsv', index=None, sep='\\t')\n",
    "val.to_csv('val.tsv', index=None, sep='\\t')\n",
    "test.to_csv('test.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6a46a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d8daf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=wiktionary_dedup.csv --character_coverage=1.0 --model_prefix=wiktionary --vocab_size=5000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: wiktionary_dedup.csv\n",
      "  input_format: \n",
      "  model_prefix: wiktionary\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 5000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: wiktionary_dedup.csv\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 32056 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=521591\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=119\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 32056 sentences.\n",
      "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(201) LOG(INFO) Initialized 24191 seed sentencepieces\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 32056\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 14936\n",
      "unigram_model_trainer.cc(491) LOG(INFO) Using 14936 sentences for EM training\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=10504 obj=7.31069 num_tokens=32394 num_tokens/piece=3.08397\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=9109 obj=6.11238 num_tokens=32470 num_tokens/piece=3.56461\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=6813 obj=6.10569 num_tokens=34740 num_tokens/piece=5.09908\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=6782 obj=6.07694 num_tokens=34764 num_tokens/piece=5.12592\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=5495 obj=6.1406 num_tokens=36728 num_tokens/piece=6.68389\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=5491 obj=6.12239 num_tokens=36738 num_tokens/piece=6.69058\n",
      "trainer_interface.cc(685) LOG(INFO) Saving model: wiktionary.model\n",
      "trainer_interface.cc(697) LOG(INFO) Saving vocabs: wiktionary.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train('--input=wiktionary_dedup.csv --character_coverage=1.0 --model_prefix=wiktionary --vocab_size=5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2153fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc6bf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.load('wiktionary.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e46b1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁', 'ผม', 'ท', 'ํา', 'การ', 'ตัด', 'คํา', 'ภาษา', 'ไทย']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode_as_pieces('ผมทำการตัดคำภาษาไทย')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f4f3bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3336518/1802340216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoneme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_as_pieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.phoneme.map(lambda x: len(sp.encode_as_pieces(x))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ddc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
